{
  "best_global_step": 3460,
  "best_metric": 0.8693183660507202,
  "best_model_checkpoint": "/kaggle/working/checkpoints/checkpoint-3460",
  "epoch": 20.0,
  "eval_steps": 173,
  "global_step": 3460,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.29048656499636893,
      "grad_norm": 3.9351003170013428,
      "learning_rate": 1.416184971098266e-05,
      "loss": 4.5301,
      "step": 50
    },
    {
      "epoch": 0.5809731299927379,
      "grad_norm": 0.4499530792236328,
      "learning_rate": 2.861271676300578e-05,
      "loss": 4.1087,
      "step": 100
    },
    {
      "epoch": 0.8714596949891068,
      "grad_norm": 0.46845707297325134,
      "learning_rate": 4.3063583815028904e-05,
      "loss": 3.1318,
      "step": 150
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.202178716659546,
      "eval_runtime": 78.2623,
      "eval_samples_per_second": 7.807,
      "eval_steps_per_second": 1.955,
      "step": 173
    },
    {
      "epoch": 1.156862745098039,
      "grad_norm": 0.5939270853996277,
      "learning_rate": 5.7514450867052025e-05,
      "loss": 2.5275,
      "step": 200
    },
    {
      "epoch": 1.4473493100944081,
      "grad_norm": 0.5856671929359436,
      "learning_rate": 7.196531791907515e-05,
      "loss": 2.1972,
      "step": 250
    },
    {
      "epoch": 1.7378358750907772,
      "grad_norm": 0.5833500027656555,
      "learning_rate": 8.641618497109827e-05,
      "loss": 1.977,
      "step": 300
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.5080868005752563,
      "eval_runtime": 78.1645,
      "eval_samples_per_second": 7.817,
      "eval_steps_per_second": 1.957,
      "step": 346
    },
    {
      "epoch": 2.0232389251997094,
      "grad_norm": 0.6973951458930969,
      "learning_rate": 9.999977099513137e-05,
      "loss": 1.8359,
      "step": 350
    },
    {
      "epoch": 2.313725490196078,
      "grad_norm": 0.731948733329773,
      "learning_rate": 9.992854200874582e-05,
      "loss": 1.7118,
      "step": 400
    },
    {
      "epoch": 2.6042120551924475,
      "grad_norm": 0.6555602550506592,
      "learning_rate": 9.97302967592907e-05,
      "loss": 1.605,
      "step": 450
    },
    {
      "epoch": 2.8946986201888163,
      "grad_norm": 0.640204668045044,
      "learning_rate": 9.94055395749467e-05,
      "loss": 1.5308,
      "step": 500
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.2518210411071777,
      "eval_runtime": 78.1064,
      "eval_samples_per_second": 7.823,
      "eval_steps_per_second": 1.959,
      "step": 519
    },
    {
      "epoch": 3.180101670297749,
      "grad_norm": 0.6286075711250305,
      "learning_rate": 9.895509662532145e-05,
      "loss": 1.4813,
      "step": 550
    },
    {
      "epoch": 3.4705882352941178,
      "grad_norm": 0.6673641800880432,
      "learning_rate": 9.838011381970623e-05,
      "loss": 1.4042,
      "step": 600
    },
    {
      "epoch": 3.7610748002904866,
      "grad_norm": 0.69920814037323,
      "learning_rate": 9.76820538919274e-05,
      "loss": 1.403,
      "step": 650
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.1436556577682495,
      "eval_runtime": 78.1427,
      "eval_samples_per_second": 7.819,
      "eval_steps_per_second": 1.958,
      "step": 692
    },
    {
      "epoch": 4.046477850399419,
      "grad_norm": 0.6850243806838989,
      "learning_rate": 9.68626926792087e-05,
      "loss": 1.3746,
      "step": 700
    },
    {
      "epoch": 4.336964415395788,
      "grad_norm": 0.5920780897140503,
      "learning_rate": 9.592411460451056e-05,
      "loss": 1.3339,
      "step": 750
    },
    {
      "epoch": 4.627450980392156,
      "grad_norm": 0.6347322463989258,
      "learning_rate": 9.486870737383944e-05,
      "loss": 1.3005,
      "step": 800
    },
    {
      "epoch": 4.917937545388526,
      "grad_norm": 0.6535143852233887,
      "learning_rate": 9.369915590201681e-05,
      "loss": 1.2855,
      "step": 850
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.074526071548462,
      "eval_runtime": 78.2771,
      "eval_samples_per_second": 7.806,
      "eval_steps_per_second": 1.955,
      "step": 865
    },
    {
      "epoch": 5.203340595497458,
      "grad_norm": 0.692198634147644,
      "learning_rate": 9.241843548236078e-05,
      "loss": 1.2655,
      "step": 900
    },
    {
      "epoch": 5.493827160493828,
      "grad_norm": 0.6167485117912292,
      "learning_rate": 9.102980421765574e-05,
      "loss": 1.2288,
      "step": 950
    },
    {
      "epoch": 5.784313725490196,
      "grad_norm": 0.6710009574890137,
      "learning_rate": 8.953679473166617e-05,
      "loss": 1.2394,
      "step": 1000
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.0247102975845337,
      "eval_runtime": 78.027,
      "eval_samples_per_second": 7.831,
      "eval_steps_per_second": 1.961,
      "step": 1038
    },
    {
      "epoch": 6.069716775599129,
      "grad_norm": 0.5812817215919495,
      "learning_rate": 8.794320518227947e-05,
      "loss": 1.1982,
      "step": 1050
    },
    {
      "epoch": 6.360203340595498,
      "grad_norm": 0.6411870718002319,
      "learning_rate": 8.625308959914054e-05,
      "loss": 1.1877,
      "step": 1100
    },
    {
      "epoch": 6.650689905591866,
      "grad_norm": 0.6035804152488708,
      "learning_rate": 8.44707475703585e-05,
      "loss": 1.1936,
      "step": 1150
    },
    {
      "epoch": 6.9411764705882355,
      "grad_norm": 0.6082407832145691,
      "learning_rate": 8.260071330452226e-05,
      "loss": 1.164,
      "step": 1200
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.9960485696792603,
      "eval_runtime": 78.0251,
      "eval_samples_per_second": 7.831,
      "eval_steps_per_second": 1.961,
      "step": 1211
    },
    {
      "epoch": 7.226579520697168,
      "grad_norm": 0.5895621180534363,
      "learning_rate": 8.064774409585075e-05,
      "loss": 1.1357,
      "step": 1250
    },
    {
      "epoch": 7.5170660856935365,
      "grad_norm": 0.6155654191970825,
      "learning_rate": 7.861680822182205e-05,
      "loss": 1.156,
      "step": 1300
    },
    {
      "epoch": 7.807552650689906,
      "grad_norm": 0.5618912577629089,
      "learning_rate": 7.65130723040693e-05,
      "loss": 1.1282,
      "step": 1350
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.9723421931266785,
      "eval_runtime": 78.3103,
      "eval_samples_per_second": 7.802,
      "eval_steps_per_second": 1.954,
      "step": 1384
    },
    {
      "epoch": 8.092955700798838,
      "grad_norm": 0.6063544154167175,
      "learning_rate": 7.43418881646968e-05,
      "loss": 1.1244,
      "step": 1400
    },
    {
      "epoch": 8.383442265795207,
      "grad_norm": 0.6697357892990112,
      "learning_rate": 7.21087792114534e-05,
      "loss": 1.1026,
      "step": 1450
    },
    {
      "epoch": 8.673928830791576,
      "grad_norm": 0.6315861940383911,
      "learning_rate": 6.98194263863986e-05,
      "loss": 1.1081,
      "step": 1500
    },
    {
      "epoch": 8.964415395787945,
      "grad_norm": 0.5840507745742798,
      "learning_rate": 6.747965371380766e-05,
      "loss": 1.1098,
      "step": 1550
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.9415310025215149,
      "eval_runtime": 78.1386,
      "eval_samples_per_second": 7.819,
      "eval_steps_per_second": 1.958,
      "step": 1557
    },
    {
      "epoch": 9.249818445896878,
      "grad_norm": 0.6394996047019958,
      "learning_rate": 6.509541348408099e-05,
      "loss": 1.084,
      "step": 1600
    },
    {
      "epoch": 9.540305010893245,
      "grad_norm": 0.6362234354019165,
      "learning_rate": 6.267277111134956e-05,
      "loss": 1.072,
      "step": 1650
    },
    {
      "epoch": 9.830791575889615,
      "grad_norm": 0.5888102054595947,
      "learning_rate": 6.021788970329806e-05,
      "loss": 1.0751,
      "step": 1700
    },
    {
      "epoch": 10.0,
      "eval_loss": 0.9290574789047241,
      "eval_runtime": 78.2065,
      "eval_samples_per_second": 7.813,
      "eval_steps_per_second": 1.956,
      "step": 1730
    },
    {
      "epoch": 10.116194625998547,
      "grad_norm": 0.6187892556190491,
      "learning_rate": 5.77370143824593e-05,
      "loss": 1.0634,
      "step": 1750
    },
    {
      "epoch": 10.406681190994917,
      "grad_norm": 0.6217638254165649,
      "learning_rate": 5.5236456398866173e-05,
      "loss": 1.0516,
      "step": 1800
    },
    {
      "epoch": 10.697167755991286,
      "grad_norm": 0.6484553217887878,
      "learning_rate": 5.272257707447775e-05,
      "loss": 1.0601,
      "step": 1850
    },
    {
      "epoch": 10.987654320987655,
      "grad_norm": 0.6615533828735352,
      "learning_rate": 5.020177162022439e-05,
      "loss": 1.042,
      "step": 1900
    },
    {
      "epoch": 11.0,
      "eval_loss": 0.9106938242912292,
      "eval_runtime": 78.1462,
      "eval_samples_per_second": 7.819,
      "eval_steps_per_second": 1.958,
      "step": 1903
    },
    {
      "epoch": 11.273057371096586,
      "grad_norm": 0.6213088631629944,
      "learning_rate": 4.768045286684067e-05,
      "loss": 1.0377,
      "step": 1950
    },
    {
      "epoch": 11.563543936092955,
      "grad_norm": 0.6325194835662842,
      "learning_rate": 4.5165034950874055e-05,
      "loss": 1.054,
      "step": 2000
    },
    {
      "epoch": 11.854030501089325,
      "grad_norm": 0.6810392141342163,
      "learning_rate": 4.266191699737189e-05,
      "loss": 1.0254,
      "step": 2050
    },
    {
      "epoch": 12.0,
      "eval_loss": 0.8977563381195068,
      "eval_runtime": 78.1404,
      "eval_samples_per_second": 7.819,
      "eval_steps_per_second": 1.958,
      "step": 2076
    },
    {
      "epoch": 12.139433551198257,
      "grad_norm": 0.6169407963752747,
      "learning_rate": 4.01774668407568e-05,
      "loss": 1.0262,
      "step": 2100
    },
    {
      "epoch": 12.429920116194626,
      "grad_norm": 0.6601319313049316,
      "learning_rate": 3.771800482530447e-05,
      "loss": 1.019,
      "step": 2150
    },
    {
      "epoch": 12.720406681190996,
      "grad_norm": 0.6248350143432617,
      "learning_rate": 3.5289787726434226e-05,
      "loss": 1.0203,
      "step": 2200
    },
    {
      "epoch": 13.0,
      "eval_loss": 0.8932816982269287,
      "eval_runtime": 78.0764,
      "eval_samples_per_second": 7.826,
      "eval_steps_per_second": 1.96,
      "step": 2249
    },
    {
      "epoch": 13.005809731299927,
      "grad_norm": 0.603935182094574,
      "learning_rate": 3.289899283371657e-05,
      "loss": 0.9985,
      "step": 2250
    },
    {
      "epoch": 13.296296296296296,
      "grad_norm": 0.6748035550117493,
      "learning_rate": 3.055170223608941e-05,
      "loss": 1.001,
      "step": 2300
    },
    {
      "epoch": 13.586782861292665,
      "grad_norm": 0.6506049633026123,
      "learning_rate": 2.825388734926117e-05,
      "loss": 1.0182,
      "step": 2350
    },
    {
      "epoch": 13.877269426289034,
      "grad_norm": 0.6031920909881592,
      "learning_rate": 2.6011393724662125e-05,
      "loss": 0.9968,
      "step": 2400
    },
    {
      "epoch": 14.0,
      "eval_loss": 0.8838792443275452,
      "eval_runtime": 78.1908,
      "eval_samples_per_second": 7.814,
      "eval_steps_per_second": 1.957,
      "step": 2422
    },
    {
      "epoch": 14.162672476397967,
      "grad_norm": 0.6263030767440796,
      "learning_rate": 2.3829926178589617e-05,
      "loss": 0.9874,
      "step": 2450
    },
    {
      "epoch": 14.453159041394336,
      "grad_norm": 0.6814208626747131,
      "learning_rate": 2.1715034279377945e-05,
      "loss": 0.9846,
      "step": 2500
    },
    {
      "epoch": 14.743645606390704,
      "grad_norm": 0.7270877361297607,
      "learning_rate": 1.9672098229513032e-05,
      "loss": 0.9971,
      "step": 2550
    },
    {
      "epoch": 15.0,
      "eval_loss": 0.8763810992240906,
      "eval_runtime": 78.1665,
      "eval_samples_per_second": 7.817,
      "eval_steps_per_second": 1.957,
      "step": 2595
    },
    {
      "epoch": 15.029048656499636,
      "grad_norm": 0.6640240550041199,
      "learning_rate": 1.770631517860719e-05,
      "loss": 0.9956,
      "step": 2600
    },
    {
      "epoch": 15.319535221496006,
      "grad_norm": 0.6505681276321411,
      "learning_rate": 1.582268600205326e-05,
      "loss": 0.9689,
      "step": 2650
    },
    {
      "epoch": 15.610021786492375,
      "grad_norm": 0.6580104827880859,
      "learning_rate": 1.4026002578992681e-05,
      "loss": 1.0011,
      "step": 2700
    },
    {
      "epoch": 15.900508351488744,
      "grad_norm": 0.6114683747291565,
      "learning_rate": 1.2320835601961928e-05,
      "loss": 0.9843,
      "step": 2750
    },
    {
      "epoch": 16.0,
      "eval_loss": 0.8746058940887451,
      "eval_runtime": 78.1498,
      "eval_samples_per_second": 7.818,
      "eval_steps_per_second": 1.958,
      "step": 2768
    },
    {
      "epoch": 16.185911401597675,
      "grad_norm": 0.6343415379524231,
      "learning_rate": 1.0711522949228991e-05,
      "loss": 0.9833,
      "step": 2800
    },
    {
      "epoch": 16.476397966594046,
      "grad_norm": 0.6824540495872498,
      "learning_rate": 9.202158649400289e-06,
      "loss": 0.9784,
      "step": 2850
    },
    {
      "epoch": 16.766884531590414,
      "grad_norm": 0.6555529236793518,
      "learning_rate": 7.796582466371616e-06,
      "loss": 0.9704,
      "step": 2900
    },
    {
      "epoch": 17.0,
      "eval_loss": 0.8737823963165283,
      "eval_runtime": 80.7538,
      "eval_samples_per_second": 7.566,
      "eval_steps_per_second": 1.895,
      "step": 2941
    },
    {
      "epoch": 17.052287581699346,
      "grad_norm": 0.6495272517204285,
      "learning_rate": 6.498370131118597e-06,
      "loss": 0.9707,
      "step": 2950
    },
    {
      "epoch": 17.342774146695714,
      "grad_norm": 0.6548720598220825,
      "learning_rate": 5.3108242451765435e-06,
      "loss": 0.9721,
      "step": 3000
    },
    {
      "epoch": 17.633260711692085,
      "grad_norm": 0.605607271194458,
      "learning_rate": 4.236965878951038e-06,
      "loss": 0.982,
      "step": 3050
    },
    {
      "epoch": 17.923747276688452,
      "grad_norm": 0.6311482191085815,
      "learning_rate": 3.2795268862326423e-06,
      "loss": 0.9725,
      "step": 3100
    },
    {
      "epoch": 18.0,
      "eval_loss": 0.8718140125274658,
      "eval_runtime": 80.5637,
      "eval_samples_per_second": 7.584,
      "eval_steps_per_second": 1.899,
      "step": 3114
    },
    {
      "epoch": 18.209150326797385,
      "grad_norm": 0.6794106960296631,
      "learning_rate": 2.44094295446744e-06,
      "loss": 0.9607,
      "step": 3150
    },
    {
      "epoch": 18.499636891793756,
      "grad_norm": 0.6415342092514038,
      "learning_rate": 1.7233474084632107e-06,
      "loss": 0.9818,
      "step": 3200
    },
    {
      "epoch": 18.790123456790123,
      "grad_norm": 0.6115143299102783,
      "learning_rate": 1.1285657832943109e-06,
      "loss": 0.9698,
      "step": 3250
    },
    {
      "epoch": 19.0,
      "eval_loss": 0.8697438836097717,
      "eval_runtime": 80.694,
      "eval_samples_per_second": 7.572,
      "eval_steps_per_second": 1.896,
      "step": 3287
    },
    {
      "epoch": 19.075526506899056,
      "grad_norm": 0.6738359332084656,
      "learning_rate": 6.581111802116902e-07,
      "loss": 0.9626,
      "step": 3300
    },
    {
      "epoch": 19.366013071895424,
      "grad_norm": 0.6718770265579224,
      "learning_rate": 3.131804173723274e-07,
      "loss": 0.9695,
      "step": 3350
    },
    {
      "epoch": 19.656499636891795,
      "grad_norm": 0.6008875370025635,
      "learning_rate": 9.465098518052773e-08,
      "loss": 0.9595,
      "step": 3400
    },
    {
      "epoch": 19.946986201888162,
      "grad_norm": 0.6929649710655212,
      "learning_rate": 3.07881398656229e-09,
      "loss": 0.9817,
      "step": 3450
    },
    {
      "epoch": 20.0,
      "eval_loss": 0.8693183660507202,
      "eval_runtime": 80.6488,
      "eval_samples_per_second": 7.576,
      "eval_steps_per_second": 1.897,
      "step": 3460
    }
  ],
  "logging_steps": 50,
  "max_steps": 3460,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 173,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6.66669611483136e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
