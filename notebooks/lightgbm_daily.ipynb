{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup dan Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"Library berhasil diimport\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data yang Sudah Diproses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed daily trends data\n",
    "# Ganti dengan path file processed Anda\n",
    "data_path = '../data/processed/daily_trends_processed_latest.csv'\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values(['keyword', 'category', 'date'])\n",
    "\n",
    "print(f\"Shape data: {df.shape}\")\n",
    "print(f\"Rentang tanggal: {df['date'].min()} sampai {df['date'].max()}\")\n",
    "print(f\"Jumlah keywords: {df['keyword'].nunique()}\")\n",
    "print(f\"Jumlah categories: {df['category'].nunique()}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering untuk Prediksi 7 Hari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_7day(df):\n",
    "    \"\"\"\n",
    "    Buat features untuk prediksi 7 hari ke depan\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Time-based features\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['dayofweek'] = df['date'].dt.dayofweek\n",
    "    df['quarter'] = df['date'].dt.quarter\n",
    "    df['weekofyear'] = df['date'].dt.isocalendar().week\n",
    "    df['is_weekend'] = df['dayofweek'].isin([5, 6]).astype(int)\n",
    "    \n",
    "    # Lag features (30 hari untuk prediksi 7 hari)\n",
    "    for lag in [1, 2, 3, 7, 14, 21, 30]:\n",
    "        df[f'lag_{lag}'] = df.groupby(['keyword', 'category'])['interest_value'].shift(lag)\n",
    "    \n",
    "    # Rolling statistics (window lebih besar untuk stabilitas)\n",
    "    for window in [7, 14, 30]:\n",
    "        df[f'rolling_mean_{window}'] = df.groupby(['keyword', 'category'])['interest_value'].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).mean()\n",
    "        )\n",
    "        df[f'rolling_std_{window}'] = df.groupby(['keyword', 'category'])['interest_value'].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).std()\n",
    "        )\n",
    "        df[f'rolling_max_{window}'] = df.groupby(['keyword', 'category'])['interest_value'].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).max()\n",
    "        )\n",
    "        df[f'rolling_min_{window}'] = df.groupby(['keyword', 'category'])['interest_value'].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).min()\n",
    "        )\n",
    "    \n",
    "    # Trend features\n",
    "    df['diff_1'] = df.groupby(['keyword', 'category'])['interest_value'].diff(1)\n",
    "    df['diff_7'] = df.groupby(['keyword', 'category'])['interest_value'].diff(7)\n",
    "    \n",
    "    # Target: interest_value 7 hari ke depan\n",
    "    df['target_7d'] = df.groupby(['keyword', 'category'])['interest_value'].shift(-7)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create features\n",
    "df = create_features_7day(df)\n",
    "\n",
    "# Drop rows dengan NaN\n",
    "df = df.dropna()\n",
    "\n",
    "print(f\"Features berhasil dibuat. Shape baru: {df.shape}\")\n",
    "print(f\"Jumlah kolom features: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Persiapan Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features dan target\n",
    "feature_cols = [\n",
    "    'day', 'month', 'year', 'dayofweek', 'quarter', 'weekofyear', 'is_weekend',\n",
    "    'lag_1', 'lag_2', 'lag_3', 'lag_7', 'lag_14', 'lag_21', 'lag_30',\n",
    "    'rolling_mean_7', 'rolling_mean_14', 'rolling_mean_30',\n",
    "    'rolling_std_7', 'rolling_std_14', 'rolling_std_30',\n",
    "    'rolling_max_7', 'rolling_max_14', 'rolling_max_30',\n",
    "    'rolling_min_7', 'rolling_min_14', 'rolling_min_30',\n",
    "    'diff_1', 'diff_7'\n",
    "]\n",
    "\n",
    "categorical_features = ['keyword', 'category', 'dayofweek', 'month', 'quarter']\n",
    "\n",
    "# Encode categorical features\n",
    "for col in categorical_features:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "# Time-based split (80% train, 20% test)\n",
    "split_date = df['date'].quantile(0.8)\n",
    "\n",
    "train_df = df[df['date'] < split_date]\n",
    "test_df = df[df['date'] >= split_date]\n",
    "\n",
    "X_train = train_df[feature_cols + categorical_features]\n",
    "y_train = train_df['target_7d']\n",
    "\n",
    "X_test = test_df[feature_cols + categorical_features]\n",
    "y_test = test_df['target_7d']\n",
    "\n",
    "print(f\"Train set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Periode train: {train_df['date'].min()} sampai {train_df['date'].max()}\")\n",
    "print(f\"Periode test: {test_df['date'].min()} sampai {test_df['date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Model LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM parameters\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Create datasets\n",
    "train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_features)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data, categorical_feature=categorical_features)\n",
    "\n",
    "# Train model\n",
    "print(\"Training model LightGBM untuk prediksi 7 hari...\")\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[train_data, test_data],\n",
    "    valid_names=['train', 'test'],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(period=100)]\n",
    ")\n",
    "\n",
    "print(\"\\nTraining selesai\")\n",
    "print(f\"Best iteration: {model.best_iteration}\")\n",
    "print(f\"Best RMSE: {model.best_score['test']['rmse']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediksi\n",
    "y_pred_train = model.predict(X_train, num_iteration=model.best_iteration)\n",
    "y_pred_test = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "# Hitung metrik\n",
    "def calculate_metrics(y_true, y_pred, dataset_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-10))) * 100\n",
    "    \n",
    "    print(f\"\\nMetrik {dataset_name}:\")\n",
    "    print(f\"  MAE:  {mae:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  R2:   {r2:.4f}\")\n",
    "    print(f\"  MAPE: {mape:.2f}%\")\n",
    "    \n",
    "    return {'MAE': mae, 'RMSE': rmse, 'R2': r2, 'MAPE': mape}\n",
    "\n",
    "train_metrics = calculate_metrics(y_train, y_pred_train, \"Train\")\n",
    "test_metrics = calculate_metrics(y_test, y_pred_test, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': model.feature_name(),\n",
    "    'importance': model.feature_importance(importance_type='gain')\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=importance_df.head(20), x='importance', y='feature')\n",
    "plt.title('Top 20 Feature Importance - Prediksi 7 Hari', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Importance (Gain)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Features Paling Penting:\")\n",
    "print(importance_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualisasi Prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Actual vs Predicted\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Train set\n",
    "axes[0].scatter(y_train, y_pred_train, alpha=0.3, s=10)\n",
    "axes[0].plot([0, 100], [0, 100], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Interest Value')\n",
    "axes[0].set_ylabel('Predicted Interest Value (7 hari)')\n",
    "axes[0].set_title(f'Train Set (R2 = {train_metrics[\"R2\"]:.4f})')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Test set\n",
    "axes[1].scatter(y_test, y_pred_test, alpha=0.3, s=10, color='orange')\n",
    "axes[1].plot([0, 100], [0, 100], 'r--', lw=2)\n",
    "axes[1].set_xlabel('Actual Interest Value')\n",
    "axes[1].set_ylabel('Predicted Interest Value (7 hari)')\n",
    "axes[1].set_title(f'Test Set (R2 = {test_metrics[\"R2\"]:.4f})')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series plot untuk sample keyword\n",
    "sample_keyword = test_df['keyword'].iloc[0]\n",
    "sample_category = test_df['category'].iloc[0]\n",
    "\n",
    "sample_data = test_df[\n",
    "    (test_df['keyword'] == sample_keyword) & \n",
    "    (test_df['category'] == sample_category)\n",
    "].copy().head(30)  # Ambil 30 hari untuk visualisasi\n",
    "\n",
    "sample_data['predicted_7d'] = model.predict(\n",
    "    sample_data[feature_cols + categorical_features],\n",
    "    num_iteration=model.best_iteration\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(sample_data['date'], sample_data['target_7d'], label='Actual (7 hari ke depan)', marker='o', linewidth=2)\n",
    "plt.plot(sample_data['date'], sample_data['predicted_7d'], label='Predicted (7 hari ke depan)', marker='s', linewidth=2, alpha=0.7)\n",
    "plt.title(f'Prediksi 7 Hari: \"{sample_keyword}\" ({sample_category})', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Tanggal')\n",
    "plt.ylabel('Interest Value')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Identifikasi Hari Terbaik untuk Posting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mendapatkan rekomendasi hari terbaik\n",
    "def get_best_days(df, model, feature_cols, categorical_features, keyword, category, n_days=7):\n",
    "    \"\"\"\n",
    "    Prediksi dan rekomendasikan hari terbaik untuk posting\n",
    "    \"\"\"\n",
    "    # Filter data untuk keyword dan category tertentu\n",
    "    latest_data = df[\n",
    "        (df['keyword'] == keyword) & \n",
    "        (df['category'] == category)\n",
    "    ].tail(1)\n",
    "    \n",
    "    if len(latest_data) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Prediksi\n",
    "    predicted_value = model.predict(\n",
    "        latest_data[feature_cols + categorical_features],\n",
    "        num_iteration=model.best_iteration\n",
    "    )[0]\n",
    "    \n",
    "    # Tanggal 7 hari ke depan\n",
    "    future_date = latest_data['date'].iloc[0] + pd.Timedelta(days=7)\n",
    "    day_name = future_date.strftime('%A, %d %B %Y')\n",
    "    \n",
    "    return {\n",
    "        'keyword': keyword,\n",
    "        'category': category,\n",
    "        'current_date': latest_data['date'].iloc[0],\n",
    "        'predicted_date': future_date,\n",
    "        'day_name': day_name,\n",
    "        'predicted_interest': predicted_value,\n",
    "        'recommendation': 'POSTING' if predicted_value > 60 else 'HINDARI' if predicted_value < 40 else 'NETRAL'\n",
    "    }\n",
    "\n",
    "# Test untuk beberapa keywords\n",
    "sample_keywords = test_df[['keyword', 'category']].drop_duplicates().head(5)\n",
    "\n",
    "print(\"\\nRekomendasi Waktu Posting (7 Hari ke Depan):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "recommendations = []\n",
    "for _, row in sample_keywords.iterrows():\n",
    "    rec = get_best_days(test_df, model, feature_cols, categorical_features, \n",
    "                        row['keyword'], row['category'])\n",
    "    if rec:\n",
    "        recommendations.append(rec)\n",
    "        print(f\"\\nKeyword: {rec['keyword']} | Category: {rec['category']}\")\n",
    "        print(f\"  Tanggal Prediksi: {rec['day_name']}\")\n",
    "        print(f\"  Predicted Interest: {rec['predicted_interest']:.2f}\")\n",
    "        print(f\"  Rekomendasi: {rec['recommendation']}\")\n",
    "\n",
    "# Convert ke DataFrame\n",
    "rec_df = pd.DataFrame(recommendations)\n",
    "rec_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Simpan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan model\n",
    "model_path = '../models/lightgbm_daily_7days.txt'\n",
    "model.save_model(model_path)\n",
    "\n",
    "# Simpan metrics\n",
    "metrics = {\n",
    "    'model': 'LightGBM',\n",
    "    'forecast_horizon': '7 days',\n",
    "    'train': train_metrics,\n",
    "    'test': test_metrics,\n",
    "    'feature_importance': importance_df.to_dict('records')[:20]\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../models/lightgbm_daily_7days_metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"Model disimpan ke: {model_path}\")\n",
    "print(f\"Metrics disimpan ke: ../models/lightgbm_daily_7days_metrics.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Ringkasan\n",
    "\n",
    "### Performa Model:\n",
    "- Algoritma: LightGBM\n",
    "- Forecast Horizon: 7 hari ke depan\n",
    "- Test RMSE: Lihat output di atas\n",
    "- Test R2: Lihat output di atas\n",
    "- Waktu Training: Cepat (biasanya < 1 menit)\n",
    "\n",
    "### Output Model:\n",
    "- Prediksi interest value 7 hari ke depan\n",
    "- Rekomendasi: POSTING / HINDARI / NETRAL\n",
    "- Untuk ensemble dengan model lain (LSTM, Neural Prophet)\n",
    "\n",
    "### Next Steps:\n",
    "1. Bandingkan dengan LSTM dan Neural Prophet (forecast horizon sama: 7 hari)\n",
    "2. Ensemble 3 model untuk prediksi lebih robust\n",
    "3. Kombinasikan dengan hourly model untuk rekomendasi jam posting\n",
    "4. Deploy untuk production"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
