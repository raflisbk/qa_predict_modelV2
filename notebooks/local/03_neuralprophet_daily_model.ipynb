{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Trends Prediction - Neural Prophet Model\n",
    "\n",
    "This notebook trains a Neural Prophet model to forecast daily interest values.\n",
    "\n",
    "**Algorithm**: Neural Prophet (Facebook's time series forecasting)\n",
    "- Built on PyTorch\n",
    "- Combines traditional time series decomposition with neural networks\n",
    "- Handles seasonality, trends, and holidays automatically\n",
    "- Easy to use API similar to Prophet\n",
    "\n",
    "**Target**: Forecast interest_value (0-100) for future days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from neuralprophet import NeuralProphet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed daily trends data\n",
    "data_path = '../data/processed/daily_trends_processed_latest.csv'\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values(['keyword', 'category', 'date'])\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"Keywords: {df['keyword'].nunique()}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for Neural Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Prophet requires specific column names: 'ds' (date) and 'y' (target)\n",
    "# We'll train a model for a specific keyword/category\n",
    "\n",
    "sample_keyword = df['keyword'].iloc[0]\n",
    "sample_category = df['category'].iloc[0]\n",
    "\n",
    "# Filter data\n",
    "keyword_data = df[\n",
    "    (df['keyword'] == sample_keyword) & \n",
    "    (df['category'] == sample_category)\n",
    "].copy()\n",
    "\n",
    "# Prepare for Neural Prophet\n",
    "prophet_df = keyword_data[['date', 'interest_value']].copy()\n",
    "prophet_df.columns = ['ds', 'y']\n",
    "prophet_df = prophet_df.sort_values('ds').reset_index(drop=True)\n",
    "\n",
    "print(f\"Training model for: {sample_keyword} ({sample_category})\")\n",
    "print(f\"Data points: {len(prophet_df)}\")\n",
    "print(f\"Date range: {prophet_df['ds'].min()} to {prophet_df['ds'].max()}\")\n",
    "\n",
    "prophet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based split (80% train, 20% test)\n",
    "split_idx = int(len(prophet_df) * 0.8)\n",
    "\n",
    "train_df = prophet_df[:split_idx].copy()\n",
    "test_df = prophet_df[split_idx:].copy()\n",
    "\n",
    "print(f\"Train set: {len(train_df)} days\")\n",
    "print(f\"Test set: {len(test_df)} days\")\n",
    "print(f\"Train period: {train_df['ds'].min()} to {train_df['ds'].max()}\")\n",
    "print(f\"Test period: {test_df['ds'].min()} to {test_df['ds'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize and Configure Neural Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Neural Prophet model\n",
    "model = NeuralProphet(\n",
    "    # Growth settings\n",
    "    growth='linear',  # or 'discontinuous' for trend changes\n",
    "    \n",
    "    # Seasonality\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False,\n",
    "    \n",
    "    # Neural network settings\n",
    "    n_lags=30,  # Use 30 days of autoregressive lags\n",
    "    n_forecasts=7,  # Forecast 7 days ahead\n",
    "    \n",
    "    # Training settings\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    learning_rate=0.01,\n",
    "    \n",
    "    # Regularization\n",
    "    trend_reg=1,\n",
    "    \n",
    "    # Other settings\n",
    "    loss_func='MSE',\n",
    "    normalize='auto'\n",
    ")\n",
    "\n",
    "print(\"Neural Prophet model initialized\")\n",
    "print(f\"Autoregressive lags: {model.n_lags}\")\n",
    "print(f\"Forecast horizon: {model.n_forecasts} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "print(\"Training Neural Prophet model...\")\n",
    "metrics = model.fit(train_df, freq='D', validation_df=test_df)\n",
    "\n",
    "print(\"\\nModel training completed\")\n",
    "print(f\"Final training loss: {metrics['Loss'].iloc[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Metrics Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training metrics\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(metrics['Loss'], label='Training Loss', linewidth=2)\n",
    "if 'Loss_val' in metrics.columns:\n",
    "    axes[0].plot(metrics['Loss_val'], label='Validation Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# MAE\n",
    "if 'MAE' in metrics.columns:\n",
    "    axes[1].plot(metrics['MAE'], label='Training MAE', linewidth=2)\n",
    "if 'MAE_val' in metrics.columns:\n",
    "    axes[1].plot(metrics['MAE_val'], label='Validation MAE', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].set_title('Training and Validation MAE')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "forecast = model.predict(test_df)\n",
    "\n",
    "print(f\"Forecast shape: {forecast.shape}\")\n",
    "print(f\"Forecast columns: {forecast.columns.tolist()}\")\n",
    "\n",
    "forecast.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract actual and predicted values\n",
    "# Neural Prophet returns yhat1 for 1-step ahead forecast\n",
    "actual = forecast['y'].values\n",
    "predicted = forecast['yhat1'].values\n",
    "\n",
    "# Remove NaN values\n",
    "mask = ~np.isnan(actual) & ~np.isnan(predicted)\n",
    "actual = actual[mask]\n",
    "predicted = predicted[mask]\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(actual, predicted)\n",
    "rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "r2 = r2_score(actual, predicted)\n",
    "mape = np.mean(np.abs((actual - predicted) / (actual + 1e-10))) * 100\n",
    "\n",
    "print(f\"\\nTest Set Metrics:\")\n",
    "print(f\"  MAE:  {mae:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}\")\n",
    "print(f\"  R2:   {r2:.4f}\")\n",
    "print(f\"  MAPE: {mape:.2f}%\")\n",
    "\n",
    "test_metrics = {'MAE': mae, 'RMSE': rmse, 'R2': r2, 'MAPE': mape}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot forecast\n",
    "fig = model.plot(forecast)\n",
    "plt.title(f'Neural Prophet Forecast: {sample_keyword} ({sample_category})', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Actual vs Predicted\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(actual, predicted, alpha=0.5, s=30)\n",
    "plt.plot([0, 100], [0, 100], 'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual Interest Value', fontsize=12)\n",
    "plt.ylabel('Predicted Interest Value', fontsize=12)\n",
    "plt.title(f'Actual vs Predicted (R2 = {r2:.4f})', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot components (trend, seasonality)\n",
    "fig_comp = model.plot_components(forecast)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameters (if available)\n",
    "fig_param = model.plot_parameters()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Future Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make future forecast (30 days ahead)\n",
    "future = model.make_future_dataframe(prophet_df, periods=30, n_historic_predictions=True)\n",
    "forecast_future = model.predict(future)\n",
    "\n",
    "print(f\"Future forecast shape: {forecast_future.shape}\")\n",
    "print(f\"Forecast extends to: {forecast_future['ds'].max()}\")\n",
    "\n",
    "# Plot future forecast\n",
    "fig = model.plot(forecast_future)\n",
    "plt.title(f'30-Day Future Forecast: {sample_keyword}', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save Model and Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('../models/neuralprophet_daily_model.pt')\n",
    "print(f\"Model saved to: ../models/neuralprophet_daily_model.pt\")\n",
    "\n",
    "# Save forecast\n",
    "forecast_future.to_csv('../models/neuralprophet_forecast.csv', index=False)\n",
    "print(f\"Forecast saved to: ../models/neuralprophet_forecast.csv\")\n",
    "\n",
    "# Save metrics\n",
    "import json\n",
    "metrics_dict = {\n",
    "    'test': test_metrics,\n",
    "    'n_lags': model.n_lags,\n",
    "    'n_forecasts': model.n_forecasts,\n",
    "    'keyword': sample_keyword,\n",
    "    'category': sample_category\n",
    "}\n",
    "\n",
    "with open('../models/neuralprophet_daily_metrics.json', 'w') as f:\n",
    "    json.dump(metrics_dict, f, indent=2)\n",
    "\n",
    "print(f\"Metrics saved to: ../models/neuralprophet_daily_metrics.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Load Saved Model (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load saved model for inference\n",
    "# loaded_model = NeuralProphet.load('../models/neuralprophet_daily_model.pt')\n",
    "# new_forecast = loaded_model.predict(new_data)\n",
    "\n",
    "print(\"To load model: NeuralProphet.load('path/to/model.pt')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Summary\n",
    "\n",
    "### Model Performance:\n",
    "- Algorithm: Neural Prophet\n",
    "- Autoregressive Lags: 30 days\n",
    "- Forecast Horizon: 7 days\n",
    "- Test RMSE: Check output above\n",
    "- Test R2: Check output above\n",
    "\n",
    "### Advantages:\n",
    "- Automatic seasonality detection\n",
    "- Handles trends and changepoints\n",
    "- Easy to interpret (decomposition into components)\n",
    "- Built-in uncertainty quantification\n",
    "- Fast training with PyTorch\n",
    "\n",
    "### Limitations:\n",
    "- Requires regular time series (no gaps)\n",
    "- May need tuning for specific patterns\n",
    "- Less flexible than pure deep learning\n",
    "\n",
    "### Next Steps:\n",
    "1. Add custom seasonalities (monthly, quarterly)\n",
    "2. Include external regressors (holidays, events)\n",
    "3. Tune hyperparameters (n_lags, learning_rate, etc.)\n",
    "4. Train models for all keywords/categories\n",
    "5. Compare with LightGBM and LSTM results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
